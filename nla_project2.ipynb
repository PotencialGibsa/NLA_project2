{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM на основе тензорного CP разложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorly as tl\n",
    "import functools\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CP_LinearSVM:\n",
    "    def __init__(self, CP_rank):\n",
    "        self.cp_rank = CP_rank\n",
    "\n",
    "               \n",
    "    def createFactors(self, tensor):\n",
    "        n_dim = tensor.ndim\n",
    "        dictionary = {}\n",
    "        \n",
    "        for i in range(1, n_dim):\n",
    "            array = np.random.randn(tensor.shape[i], self.cp_rank)\n",
    "            dictionary[i] = array\n",
    "            \n",
    "        return dictionary\n",
    "    \n",
    "    \n",
    "    def tensorUnfold(self, tensor, mode):\n",
    "        n_dim = tensor.ndim\n",
    "        indices = np.arange(n_dim).tolist()\n",
    "        element = indices.pop(mode)\n",
    "        sample_index = indices.pop(0)\n",
    "        new_indices = ([sample_index] + [element] + indices)    \n",
    "        \n",
    "        samples = tensor.shape[0]\n",
    "        return np.transpose(tensor, new_indices).reshape(samples, tensor.shape[mode], -1)\n",
    "        \n",
    " \n",
    "    def getsvmFunctions(self, tensor):\n",
    "        n_dim = tensor.ndim\n",
    "        \n",
    "        optimize_functions = []\n",
    "        \n",
    "        for i in range(1, n_dim):\n",
    "            def optimizer(opt_mat, dictionary, CP_rank, C, X, Y, i=i):\n",
    "                samples = X.shape[0]\n",
    "     \n",
    "                vec_matrix = np.reshape(opt_mat, (CP_rank*X.shape[i], 1))\n",
    "                matricize_X = self.tensorUnfold(tensor=X, mode=i)\n",
    "                \n",
    "                temp_dict = dict(dictionary)\n",
    "                del temp_dict[i]\n",
    "    \n",
    "                new_matrices = list(temp_dict.values())\n",
    "                new_matrices = new_matrices[::-1]\n",
    "    \n",
    "                khatri_product = tl.tenalg.khatri_rao(new_matrices)\n",
    "                X_khatri = tl.tenalg.mode_dot(matricize_X, khatri_product.T, 2)\n",
    "                vec_X_khatri = np.reshape(X_khatri, (samples, CP_rank*X.shape[i]))\n",
    "                Y_hat = vec_X_khatri @ vec_matrix\n",
    "    \n",
    "                error = (1/samples)*np.sum(np.maximum(0, (1-Y.squeeze()*Y_hat.squeeze()))) + 0.5*C*np.linalg.norm(vec_matrix)**2\n",
    "    \n",
    "                return error\n",
    "        \n",
    "            optimize_functions.append(optimizer)\n",
    "            \n",
    "        return optimize_functions\n",
    "        \n",
    "\n",
    "    def fit(self, tensor, labels, C=1, max_iterations=200, sensitivity=1e-6, print_iterations=True):\n",
    "        iterations = 0\n",
    "        error = 1\n",
    "        current_error = 0\n",
    "        n_dim = tensor.ndim        \n",
    "        \n",
    "        init_dict = self.createFactors(tensor=tensor)\n",
    "        optimize_functions = self.getsvmFunctions(tensor=tensor)\n",
    "        \n",
    "        while (error > sensitivity) and (iterations < max_iterations):\n",
    "            prev_error = current_error\n",
    "            \n",
    "            for i in range(1, n_dim):\n",
    "                initial_guess = init_dict[i]\n",
    "                solve = functools.partial(optimize_functions[i-1], dictionary=init_dict, \n",
    "                                          CP_rank=self.cp_rank, C=C, X=tensor, Y=labels)\n",
    "                solver = minimize(solve, initial_guess, method='SLSQP', tol=0.0001)\n",
    "                initial_guess = np.reshape(solver.x, (initial_guess.shape))\n",
    "                init_dict[i] = initial_guess\n",
    "                \n",
    "            current_error = solver.fun\n",
    "            error = abs(prev_error - current_error)\n",
    "            iterations += 1\n",
    "            \n",
    "            if print_iterations:\n",
    "                print('Current Iteration: ' + str(iterations))\n",
    "                print('Current Difference in Error Value: '+ str(error) + str('\\n'))\n",
    "                \n",
    "        return init_dict    \n",
    "        \n",
    "    \n",
    "    def reconstructTensor(self, solved_dict, tensor_n_dim):\n",
    "        if tensor_n_dim == 2:\n",
    "            A = solved_dict[1]\n",
    "            B = solved_dict[2]\n",
    "            \n",
    "            recon_beta = np.zeros((A.shape[0], B.shape[0]))\n",
    "            \n",
    "            for i in range(tensor_n_dim):\n",
    "                solved_prod = np.prod(np.ix_(A[:, i], B[:, i]))\n",
    "                recon_beta += solved_prod\n",
    "                \n",
    "            return recon_beta\n",
    "                \n",
    "        elif tensor_n_dim == 3:\n",
    "            A = solved_dict[1]\n",
    "            B = solved_dict[2]\n",
    "            C = solved_dict[3]\n",
    "            \n",
    "            recon_beta = np.zeros((A.shape[0], B.shape[0], C.shape[0]))\n",
    "            \n",
    "            for i in range(tensor_n_dim):\n",
    "                solved_prod = np.prod(np.ix_(A[:, i], B[:, i], C[:, i]))\n",
    "                recon_beta += solved_prod\n",
    "                \n",
    "            return recon_beta       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обычный SVM\n",
    "\n",
    "def svmSolver(beta, C, vec_X, Y):\n",
    "    samples = vec_X.shape[0]\n",
    "    Y_hat = vec_X @ beta \n",
    "    error = (1/samples)*np.sum(np.maximum(0, (1-Y.squeeze()*Y_hat.squeeze()))) + 0.5*C*np.linalg.norm(beta)**2\n",
    "    \n",
    "    return error\n",
    "    \n",
    "    \n",
    "def svmfit(vec_X, Y, C=1):\n",
    "    init_beta = np.random.randn(vec_X.shape[1], 1)\n",
    "    partial_solver = functools.partial(svmSolver, C=C, vec_X=vec_X, Y=Y)\n",
    "    solved = minimize(partial_solver, init_beta, method='SLSQP')\n",
    "    opt_weights = solved.x\n",
    "    \n",
    "    return opt_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMetrics(recon_tensor, true_tensor):\n",
    "    recon_tensor = recon_tensor / np.linalg.norm(recon_tensor, 'fro')\n",
    "    \n",
    "    mse_val = np.linalg.norm(recon_tensor-true_tensor)**2\n",
    "    \n",
    "    vec_recon = np.reshape(recon_tensor, (-1, 1))\n",
    "    vec_true = np.reshape(true_tensor, (-1, 1))\n",
    "        \n",
    "    recon_norm = np.linalg.norm(vec_recon)\n",
    "    true_norm = np.linalg.norm(vec_true)\n",
    "    \n",
    "    cos_dis = (vec_true.T @ vec_recon) / (true_norm*recon_norm)\n",
    "        \n",
    "    num = np.linalg.norm((true_tensor-recon_tensor), 'fro')\n",
    "    den = np.linalg.norm(true_tensor, 'fro')\n",
    "        \n",
    "    recon_err = num / den\n",
    "    \n",
    "    return mse_val, cos_dis, recon_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На сгенерированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(sample_size, noise_variance):\n",
    "    A = np.array([[1]*15, [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]]).T\n",
    "    B = np.array([[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1]*15]).T\n",
    "    x_shape = A.shape[0]\n",
    "    y_shape = B.shape[0]\n",
    "    \n",
    "    X_train = np.random.randn(sample_size, x_shape, y_shape) \n",
    "    X_train_vec = np.reshape(X_train, (sample_size, x_shape*y_shape))\n",
    "    \n",
    "    cross_beta = A @ B.T\n",
    "    vec_cross_beta = np.reshape(cross_beta, (x_shape*y_shape, 1))\n",
    "    cross_norm = np.linalg.norm(cross_beta, 'fro')\n",
    "    cross_beta = cross_beta / cross_norm\n",
    "    Y_soft = np.zeros((sample_size, 1))\n",
    "    \n",
    "    for i in range(sample_size):\n",
    "        epsilon = noise_variance * np.random.randn(1, 1)\n",
    "        x_i = X_train_vec[i, :]\n",
    "        y_i = (x_i @ vec_cross_beta) + epsilon\n",
    "        Y_soft[i, :] = y_i\n",
    "        \n",
    "    Y_hard = np.sign(Y_soft)\n",
    "    \n",
    "    return cross_beta, X_train, Y_hard, Y_soft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed CP-SVM 4.105848789215088 s\n",
      "CP svm params =  60\n",
      "CP-SVM acc 0.8766666666666667\n",
      "time infer CP-SVM 0.003003358840942383 s\n",
      "time consumed SVM 4.182396650314331 s\n",
      "SVM acc 0.9266666666666666\n",
      "time infer SVM 0.0009992122650146484 s\n",
      "Traditional svm params =  (225,)\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1500\n",
    "variance = 1 #1.5\n",
    "CP_rank = 2\n",
    "\n",
    "true_pred, X, Y_hard, Y_soft = generate_data(sample_size, variance)\n",
    "\n",
    "CP_SVM = CP_LinearSVM(CP_rank=CP_rank) \n",
    "start = time.time()\n",
    "svm_dict = CP_SVM.fit(X, Y_hard, print_iterations=False) \n",
    "cp_svm_reconstructed = CP_SVM.reconstructTensor(solved_dict=svm_dict, tensor_n_dim=2) \n",
    "print(f\"time consumed CP-SVM {time.time() - start} s\")\n",
    "\n",
    "params = 0\n",
    "for i in svm_dict:\n",
    "    params += svm_dict[i].size\n",
    "print('CP svm params = ', params)\n",
    "\n",
    "# print(np.dot(cp_svm_reconstructed.reshape((1,15,15)), X).shape)\n",
    "# print(np.inner(cp_svm_reconstructed, X).shape)\n",
    "# y_pred = []\n",
    "# for i in\n",
    "start = time.time()\n",
    "y_pred = np.inner(cp_svm_reconstructed.reshape(-1), np.reshape(X, (sample_size, X.shape[1]*X.shape[2])))\n",
    "y_pred_sign = np.sign(y_pred)\n",
    "\n",
    "print('CP-SVM acc', accuracy_score(Y_hard.reshape(-1), y_pred_sign))\n",
    "print(f\"time infer CP-SVM {time.time() - start} s\")\n",
    "\n",
    "\n",
    "\n",
    "# training traditional SVM model\n",
    "# vec_SVM = traditionalML(algorithm='Linear SVM') # instantiating class\n",
    "vec_X = np.reshape(X, (sample_size, -1)) # vectorizing data\n",
    "start = time.time()\n",
    "vec_svm_params = svmfit(vec_X, Y_hard)\n",
    "print(f\"time consumed SVM {time.time() - start} s\")\n",
    "vec_svm_reconstructed = np.reshape(vec_svm_params, (cp_svm_reconstructed.shape))\n",
    "\n",
    "start = time.time()\n",
    "y_pred2 = np.sign(np.inner(vec_svm_params, np.reshape(X, (sample_size, X.shape[1]*X.shape[2]))))\n",
    "print('SVM acc', accuracy_score(Y_hard.reshape(-1), y_pred2))\n",
    "print(f\"time infer SVM {time.time() - start} s\")\n",
    "\n",
    "\n",
    "\n",
    "print('Traditional svm params = ', vec_svm_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP MSE: 0.15359745753730597\n",
      "Traditional MSE: 0.18303336006493165 \n",
      "\n",
      "CP Cosine Distance: [[0.92320127]]\n",
      "Traditional Cosine Distance: [[0.90848332]] \n",
      "\n",
      "CP Reconstruction Error: 0.39191511521923467\n",
      "Traditional Reconstruction Error: 0.4278239825733612 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP4UlEQVR4nO3dfbBcdX3H8feHBITwlFCeQhJ5linYjtAMg5RRprHIk8TO0DaMSBCROB0rODgYSsdknD4gUrG2TiECSmsKIgJSC5WAMh2mJAXSBEgCJNBIEm8IiBKeKqR8+8c5FzfbvZvLnnP2bvh+XjM79+ye3+7ve8/ez56HPff8FBGY2TvfDmNdgJn1h8NuloTDbpaEw26WhMNuloTDbpaEw261kXSQpJA0vrx/l6TZY12XFRz2MSLp5Zbbm5Jea7n/sQb7PVfS/5b9bJa0TNLpTfQVEadExA2jqGmtpA81UYP9msM+RiJit+Eb8AzwkZbHFg63G15L1uyBst+JwHXAzZImtTdqqO9abQ81DgqHfcBIOlHSeklfkLQR+Fa5Nr6/rV1IOqycfpekKyU9I+lZSVdL2mVbfUXEm8D1wC7AoZLmS7pF0nckbQbOlbSnpOskDUnaIOkvJI0r+x1X9vu8pKeB09pqvE/S+S33PyVplaSXJK2UdIykfwLeDfxLubVxSdn2DEkrJP2yfJ3fbHmdteXyeQR4xYEfHYd9MO0P7AUcCFwwivaXA+8B3gccBkwBvritJ5UhOR94GVhdPjwTuIVirb8Q+DawpXzdo4GTyucAfAo4vXx8OnBml77+EJgPnAPsAZwB/DwiPs7WWzZXSHoPcCNwEbAPcCfFh8FOLS95FsWHy8SI2LKt39Uc9kH1JjAvIn4VEa91ayhJFB8In4uIFyLiJeCvgFldnnacpF8CGylC8wcR8WI574GIuL1c6+8BnApcFBGvRMQm4KqW1/4j4GsRsS4iXgD+ukuf5wNXRMSDUVgTET8doe0fA/8aEYsi4g3gSoqtj+Nb2ny97Lfr8rFf8+bPYHouIv5nlG33ASYADxe5B0DAuC7PWRwRJ4wwb13L9IHAjsBQy2vv0NLmgLb2I4UXYBrwVJf5rQ5ofa2IeFPSOootlk512ig47IOp/V8RX6EINACS9m+Z9zzwGnBURGyoue91wK+AvUfYVB6iCPGwd3d53XXAoaPoE+BnwG8N3ym3XqYBG7o8x7bBm/Hbh+XAUZLeJ2lnin1f4K2DbN8ErpK0L4CkKZI+XLXTiBgC7gb+RtIeknaQdKikD5ZNbgY+K2lqeTR/bpeXuxb4vKTfUeEwSQeW854FDmlpezNwmqQZknYELqb40PmPqr9TZg77diAingS+BNxDcSDt/rYmXwDWAIvLo+j3AEfU1P05wE7ASuAXFAfvJpfzvgn8iOLDaClwa5ff4XvAXwL/DLwE3E5xEBKKff0/L4+8fz4ingDOBv6OYsvlIxQH8F6v6XdKSb54hVkOXrObJeGwmyXhsJsl4bCbJdHX79kl+WhgQyZPnrztRgNkaGhorEt4x4oIdXrcJ9W8Q8yZM2esS3hb5s+fP9YlpOPNeLMkHHazJCqFXdLJkp6QtEZSt1MlzWyM9Rz28gIG3wBOAY4EzpJ0ZF2FmVm9qqzZjwXWRMTT5TnLN1Fc+MDMBlCVsE9h6/8pXs/W/29sZgOk8a/eJF3A6C6tZGYNqhL2DWx94YKpbH1xAQAiYgGwAHxSjdlYqrIZ/yBwuKSDywsBzgLuqKcsM6tbz2v2iNgi6TMUFy8YB1wfEStqq8zMalVpnz0i7qS4zK+ZDTifQWeWhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNulkSVsd6mSfqJpJWSVki6sM7CzKxeVa4uuwW4OCKWStodeFjSoohYWVNtZlajntfsETEUEUvL6ZeAVXisN7OBVcs+u6SDgKOBJXW8npnVr/LAjpJ2A74PXBQRmzvM98COZgOgUtgl7UgR9IURcWunNh7Y0WwwVDkaL+A6YFVEfLW+ksysCVX22X8X+Djwe5KWlbdTa6rLzGpWZRTX+wHVWIuZNchn0Jkl4bCbJeGwmyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXhsJsl4bCbJVE57JLGSfovST+soyAza0Yda/YLKcZ5M7MBVinskqYCpwHX1lOOmTWl6pr9a8AlwJvVSzGzJlUZ/ul0YFNEPLyNdhdIekjSQ732ZWbVVR3+6QxJa4GbKIaB+k57o4hYEBHTI2J6hb7MrKKewx4Rl0bE1Ig4CJgF/Dgizq6tMjOrlb9nN0ui0vjswyLiPuC+Ol7LzJrhNbtZEg67WRIOu1kSDrtZEg67WRIOu1kSDrtZEg67WRIOu1kSDrtZEg67WRIOu1kSDrtZEg67WRIOu1kSDrtZErVcvGK0Jk+ezJw5c/rZZRrz5s0b6xJsAFxzzTUjzvOa3SwJh90sCYfdLImqwz9NlHSLpMclrZL0/roKM7N6VT1A97fAv0XEmZJ2AibUUJOZNaDnsEvaE/gAcC5ARLwOvF5PWWZWtyqb8QcDzwHfKsdnv1bSrjXVZWY1qxL28cAxwD9ExNHAK8Dc9katAzu++uqrFbozsyqqhH09sD4ilpT3b6EI/1ZaB3acMMG79GZjpcrAjhuBdZKOKB+aAayspSozq13Vo/F/Ciwsj8Q/DXyieklm1oRKYY+IZYDHXTfbDvgMOrMkHHazJBx2syQcdrMkHHazJBx2syQcdrMkHHazJBx2syQcdrMkHHazJBx2syQcdrMkHHazJBx2syQcdrMkHHazJBx2syQcdrMkHHazJKoO7Pg5SSskPSbpRkk711WYmdWr57BLmgJ8FpgeEe8FxgGz6irMzOpVdTN+PLCLpPEUI7j+rHpJZtaEKiPCbACuBJ4BhoAXI+Luugozs3pV2YyfBMykGM31AGBXSWd3aOeBHc0GQJXN+A8B/x0Rz0XEG8CtwPHtjTywo9lgqBL2Z4DjJE2QJIqBHVfVU5aZ1a3KPvsSimGalwKPlq+1oKa6zKxmVQd2nAfMq6kWM2uQz6AzS8JhN0tCEdG/zqT+dZbM/Pnzx7qEt2V7q3d7EhHq9LjX7GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSWwz7JKul7RJ0mMtj+0laZGk1eXPSc2WaWZVjWbN/m3g5LbH5gL3RsThwL3lfTMbYNsMe0T8O/BC28MzgRvK6RuAj9ZblpnVrdd99v0iYqic3gjsV1M9ZtaQSoNEAEREdLtqrKQLgAuq9mNm1fS6Zn9W0mSA8uemkRq2DuzYY19mVoNew34HMLucng38oJ5yzKwpo/nq7UbgAeAISeslfRK4HPh9Sasphm6+vNkyzayqbe6zR8RZI8yaUXMtZtYgn0FnloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpZErwM7fkXS45IekXSbpImNVmlmlfU6sOMi4L0R8dvAk8ClNddlZjXraWDHiLg7IraUdxcDUxuozcxqVMc++3nAXTW8jpk1qNLAjpIuA7YAC7u08cCOZgOg57BLOhc4HZgRESOO4hoRC4AF5XNGbGdmzeop7JJOBi4BPhgRr9Zbkpk1odeBHf8e2B1YJGmZpKsbrtPMKup1YMfrGqjFzBrkM+jMknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZJw2M2ScNjNknDYzZLoaWDHlnkXSwpJezdTnpnVpdeBHZE0DTgJeKbmmsysAT0N7Fi6imKgCI/yYrYd6GmfXdJMYENELK+5HjNryNse/knSBODPKDbhR9PeAzuaDYBe1uyHAgcDyyWtpRibfamk/Ts1jogFETE9Iqb3XqaZVfW21+wR8Siw7/D9MvDTI+L5Gusys5r1OrCjmW1neh3YsXX+QbVVY2aN8Rl0Zkk47GZJKKJ/58RIeg746Qiz9wYG6SDfoNUDg1eT6+luLOo5MCL26TSjr2HvRtJDg/T13KDVA4NXk+vpbtDq8Wa8WRIOu1kSgxT2BWNdQJtBqwcGrybX091A1TMw++xm1qxBWrObWYMcdrMk+h52SSdLekLSGklzO8x/l6TvlvOXSDqowVqmSfqJpJWSVki6sEObEyW9KGlZeftiU/W09LlW0qNlfw91mC9JXy+X0SOSjmmwliNafvdlkjZLuqitTaPLqNOl0STtJWmRpNXlz0kjPHd22Wa1pNkN1vMVSY+X78dtkiaO8Nyu722jIqJvN2Ac8BRwCLATsBw4sq3NnwBXl9OzgO82WM9k4JhyenfgyQ71nAj8sM/LaS2wd5f5pwJ3AQKOA5b08f3bSHHiRt+WEfAB4BjgsZbHrgDmltNzgS93eN5ewNPlz0nl9KSG6jkJGF9Of7lTPaN5b5u89XvNfiywJiKejojXgZuAmW1tZgI3lNO3ADMkqYliImIoIpaW0y8Bq4ApTfRVs5nAP0ZhMTBR0uQ+9DsDeCoiRjoLshHR+dJorX8nNwAf7fDUDwOLIuKFiPgFsIgO11Oso56IuDsitpR3F1Nc52Gg9DvsU4B1LffX8//D9VabcuG9CPxG04WVuwtHA0s6zH6/pOWS7pJ0VNO1UFzX725JD5dX+mk3muXYhFnAjSPM6/cy2i8ihsrpjcB+HdqM1XI6j2LLq5NtvbeNedsXr3gnkrQb8H3goojY3DZ7KcVm68uSTgVuBw5vuKQTImKDpH2BRZIeL9cmY0bSTsAZwKUdZo/FMnpLRISkgfgOWdJlwBZg4QhNxuy97feafQMwreX+1PKxjm0kjQf2BH7eVEGSdqQI+sKIuLV9fkRsjoiXy+k7gR2bvk5+RGwof24CbqPY/Wk1muVYt1OApRHxbPuMsVhGwLPDuy7lz00d2vR1OUk6Fzgd+FiUO+jtRvHeNqbfYX8QOFzSweWaYhZwR1ubO4Dho6ZnAj8eacFVVR4LuA5YFRFfHaHN/sPHDCQdS7HMmvzw2VXS7sPTFAd+2gfouAM4pzwqfxzwYssmbVPOYoRN+H4vo1Lr38ls4Acd2vwIOEnSpPJo/UnlY7WTdDLFpdXPiIhXR2gzmve2Of0+IkhxJPlJiqPyl5WPfYliIQHsDHwPWAP8J3BIg7WcQLEP9QiwrLydCnwa+HTZ5jPACopvDhYDxze8fA4p+1pe9ju8jFprEvCNchk+SnENwCZr2pUivHu2PNa3ZUTxITMEvEGx3/1JiuM49wKrgXuAvcq204FrW557Xvm3tAb4RIP1rKE4PjD8dzT8jdIBwJ3d3tt+3Xy6rFkSPoPOLAmH3SwJh90sCYfdLAmH3SwJh90sCYfdLIn/Azl20IjUSc7mAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp_mse_val, cp_cos_dis, cp_recon_err = evaluateMetrics(cp_svm_reconstructed, true_pred) \n",
    "vec_mse_val, vec_cos_dis, vec_recon_err = evaluateMetrics(vec_svm_reconstructed, true_pred)\n",
    "\n",
    "print('CP MSE:', cp_mse_val)\n",
    "print('Traditional MSE:', vec_mse_val, '\\n')\n",
    "\n",
    "print('CP Cosine Distance:', cp_cos_dis)\n",
    "print('Traditional Cosine Distance:', vec_cos_dis, '\\n')\n",
    "\n",
    "print('CP Reconstruction Error:', cp_recon_err)\n",
    "print('Traditional Reconstruction Error:', vec_recon_err, '\\n')\n",
    "\n",
    "\n",
    "plt.imshow(true_pred, cmap='gray')\n",
    "plt.title('True Predictor')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(cp_svm_reconstructed, cmap='gray')\n",
    "plt.title('CP Solved Predictor')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(vec_svm_reconstructed, cmap='gray')\n",
    "plt.title('Traditional Solved Predictor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=1, keepdims=True)\n",
    "    std = np.std(data, axis=1, keepdims=True)\n",
    "    data_normalized = (data - mean)/std\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = loadmat(\"./mnist-original.mat\")\n",
    "mnist_data = mnist[\"data\"].T\n",
    "mnist_label = mnist[\"label\"][0]\n",
    "\n",
    "# Используем только 750 цифр, повторяя за статьей\n",
    "# num_samples = 750\n",
    "\n",
    "# random_indices = np.random.choice(mnist_data.shape[0], num_samples, replace=False)\n",
    "\n",
    "# mnist_data = mnist_data[random_indices, :]\n",
    "# mnist_label = mnist_label[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data.shape, mnist_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7877,), (62123,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_label[mnist_label == 1].shape, mnist_label[mnist_label != 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_not1 = np.where(mnist_label != 1)[0]\n",
    "idx_1 = np.where(mnist_label == 1)[0]\n",
    "random_indices = np.random.choice(mnist_data[idx_not1].shape[0], mnist_data[idx_1].shape[0], replace=False)\n",
    "\n",
    "mnist_data = mnist_data[np.r_[random_indices, idx_1], :]\n",
    "mnist_label = mnist_label[np.r_[random_indices, idx_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set feature matrix is: (12603, 784)\n",
      "The shape of the training label vector is: (12603, 1)\n",
      "The shape of the test set feature matrix is: (3151, 784)\n",
      "The shape of the test label vector is: (3151, 1)\n",
      "The shape of the training set feature matrix is: (12603, 28, 28)\n",
      "The shape of the training label vector is: (12603,)\n",
      "The shape of the test set feature matrix is: (3151, 28, 28)\n",
      "The shape of the test label vector is: (3151,)\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных\n",
    "#Нормализуем данные\n",
    "mnist_data_normalized = normalize(mnist_data)\n",
    "#Приводим к тензорному виду 28 * 28\n",
    "mnist_data_tensor_normalized = mnist_data_normalized.reshape(mnist_data.shape[0], 28,28) \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist_data_normalized, mnist_label, test_size=0.20, random_state=42)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],1)\n",
    "\n",
    "print(\"The shape of the training set feature matrix is:\", X_train.shape)\n",
    "print(\"The shape of the training label vector is:\", Y_train.shape)\n",
    "print(\"The shape of the test set feature matrix is:\", X_test.shape)\n",
    "print(\"The shape of the test label vector is:\", Y_test.shape)\n",
    "\n",
    "Y_train_1=(Y_train==1).astype(int)\n",
    "Y_test_1=(Y_test==1).astype(int)\n",
    "\n",
    "Xt_train, Xt_test, Yt_train, Yt_test = train_test_split(mnist_data_tensor_normalized, mnist_label, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"The shape of the training set feature matrix is:\", Xt_train.shape)\n",
    "print(\"The shape of the training label vector is:\", Yt_train.shape)\n",
    "print(\"The shape of the test set feature matrix is:\", Xt_test.shape)\n",
    "print(\"The shape of the test label vector is:\", Yt_test.shape)\n",
    "\n",
    "Yt_train.reshape(Yt_train.shape[0],1)\n",
    "Yt_train=(Yt_train==1).astype(int)\n",
    "Yt_train_1=Yt_train * 2 - 1 #Делаем метки для 1 и не единицы равными 1 и -1\n",
    "\n",
    "# Creating new testing label vectors for each digit for the one-vs-all methode\n",
    "Yt_test.reshape(Yt_test.shape[0],1)\n",
    "Yt_test=(Yt_test==1).astype(int)\n",
    "Yt_test_1=Yt_test * 2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 1\n",
      "Current Difference in Error Value: 0.8634118314356274\n",
      "\n",
      "Current Iteration: 2\n",
      "Current Difference in Error Value: 0.42223021472604744\n",
      "\n",
      "Current Iteration: 3\n",
      "Current Difference in Error Value: 0.08216903695750494\n",
      "\n",
      "Current Iteration: 4\n",
      "Current Difference in Error Value: 0.05971469075101843\n",
      "\n",
      "Current Iteration: 5\n",
      "Current Difference in Error Value: 0.026802482216580215\n",
      "\n",
      "Current Iteration: 6\n",
      "Current Difference in Error Value: 0.006802178122770175\n",
      "\n",
      "Current Iteration: 7\n",
      "Current Difference in Error Value: 0.001121702062866381\n",
      "\n",
      "Current Iteration: 8\n",
      "Current Difference in Error Value: 0.0005286300430085156\n",
      "\n",
      "Current Iteration: 9\n",
      "Current Difference in Error Value: 0.0002607366402140876\n",
      "\n",
      "Current Iteration: 10\n",
      "Current Difference in Error Value: 0.00024399251364842778\n",
      "\n",
      "Current Iteration: 11\n",
      "Current Difference in Error Value: 0.0\n",
      "\n",
      "time consumed CP-SVM 186.59584212303162 s\n",
      "CP svm params =  112\n",
      "time infer CP-SVM 0.0 s\n",
      "CP-SVM acc 0.9584258965407807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "CP_rank = 2\n",
    "\n",
    "# training CP SVM model\n",
    "CP_SVM = CP_LinearSVM(CP_rank=CP_rank) # instantiating class\n",
    "start = time.time()\n",
    "svm_dict = CP_SVM.fit(Xt_train[:], Yt_train_1[:]) # fitting data (X, y)\n",
    "cp_svm_reconstructed = CP_SVM.reconstructTensor(solved_dict=svm_dict, tensor_n_dim=2) # reconstruct tensor\n",
    "print(f\"time consumed CP-SVM {time.time() - start} s\")\n",
    "\n",
    "params = 0\n",
    "for i in svm_dict:\n",
    "    params += svm_dict[i].size\n",
    "print('CP svm params = ', params)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "y_pred = np.inner(cp_svm_reconstructed.reshape(-1), np.reshape(Xt_test, (Xt_test.shape[0], Xt_test.shape[1]*Xt_test.shape[2])))\n",
    "y_pred_sign = np.sign(y_pred)\n",
    "\n",
    "print(f\"time infer CP-SVM {time.time() - start} s\")\n",
    "print('CP-SVM acc', accuracy_score(Yt_test_1.reshape(-1), y_pred_sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 1\n",
      "Current Difference in Error Value: 0.5329696914522862\n",
      "\n",
      "Current Iteration: 2\n",
      "Current Difference in Error Value: 0.21563722576709643\n",
      "\n",
      "Current Iteration: 3\n",
      "Current Difference in Error Value: 0.039827396200841636\n",
      "\n",
      "Current Iteration: 4\n",
      "Current Difference in Error Value: 0.012460240240187659\n",
      "\n",
      "Current Iteration: 5\n",
      "Current Difference in Error Value: 0.003213373677920295\n",
      "\n",
      "Current Iteration: 6\n",
      "Current Difference in Error Value: 0.0002492750814054312\n",
      "\n",
      "Current Iteration: 7\n",
      "Current Difference in Error Value: 0.003999622475955755\n",
      "\n",
      "Current Iteration: 8\n",
      "Current Difference in Error Value: 0.00026390496175704437\n",
      "\n",
      "Current Iteration: 9\n",
      "Current Difference in Error Value: 0.00011208277687191348\n",
      "\n",
      "Current Iteration: 10\n",
      "Current Difference in Error Value: 0.00024525452327645025\n",
      "\n",
      "Current Iteration: 11\n",
      "Current Difference in Error Value: 6.745220258175255e-06\n",
      "\n",
      "Current Iteration: 12\n",
      "Current Difference in Error Value: 3.843942806724954e-06\n",
      "\n",
      "Current Iteration: 13\n",
      "Current Difference in Error Value: 3.5508658910998747e-06\n",
      "\n",
      "Current Iteration: 14\n",
      "Current Difference in Error Value: 2.6855350167553915e-06\n",
      "\n",
      "Current Iteration: 15\n",
      "Current Difference in Error Value: 0.0\n",
      "\n",
      "time consumed CP-SVM 321.57797622680664 s\n",
      "CP svm params =  168\n",
      "time infer CP-SVM 0.0 s\n",
      "CP-SVM acc 0.9060615677562679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "CP_rank = 3\n",
    "\n",
    "# training CP SVM model\n",
    "CP_SVM = CP_LinearSVM(CP_rank=CP_rank) # instantiating class\n",
    "start = time.time()\n",
    "svm_dict = CP_SVM.fit(Xt_train[:], Yt_train_1[:]) # fitting data (X, y)\n",
    "cp_svm_reconstructed = CP_SVM.reconstructTensor(solved_dict=svm_dict, tensor_n_dim=2) # reconstruct tensor\n",
    "print(f\"time consumed CP-SVM {time.time() - start} s\")\n",
    "\n",
    "params = 0\n",
    "for i in svm_dict:\n",
    "    params += svm_dict[i].size\n",
    "print('CP svm params = ', params)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "y_pred = np.inner(cp_svm_reconstructed.reshape(-1), np.reshape(Xt_test, (Xt_test.shape[0], Xt_test.shape[1]*Xt_test.shape[2])))\n",
    "y_pred_sign = np.sign(y_pred)\n",
    "\n",
    "print(f\"time infer CP-SVM {time.time() - start} s\")\n",
    "print('CP-SVM acc', accuracy_score(Yt_test_1.reshape(-1), y_pred_sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed SVM 104.97408032417297 s\n",
      "SVM acc 0.9822278641701048\n",
      "time infer SVM 0.0 s\n",
      "Traditional svm params =  (784,)\n"
     ]
    }
   ],
   "source": [
    "vec_X = np.reshape(Xt_train, (Xt_train.shape[0], -1)) # vectorizing data\n",
    "start = time.time()\n",
    "vec_svm_params = svmfit(vec_X, Yt_train_1)\n",
    "print(f\"time consumed SVM {time.time() - start} s\")\n",
    "vec_svm_reconstructed = np.reshape(vec_svm_params, (cp_svm_reconstructed.shape))\n",
    "\n",
    "start = time.time()\n",
    "y_pred2 = np.sign(np.inner(vec_svm_params, np.reshape(Xt_test, (Xt_test.shape[0], Xt_test.shape[1]*Xt_test.shape[2]))))\n",
    "print('SVM acc', accuracy_score(Yt_test_1.reshape(-1), y_pred2))\n",
    "print(f\"time infer SVM {time.time() - start} s\")\n",
    "\n",
    "\n",
    "\n",
    "print('Traditional svm params = ', vec_svm_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed SVM 88.37055253982544 s\n",
      "time infer SVM 0.0009982585906982422 s\n",
      "SVM acc 0.5725166613773405\n",
      "Traditional svm params =  (784,)\n"
     ]
    }
   ],
   "source": [
    "# model_1 = LogRegModel(X_train[:], X_test[:], Y_train_1[:], Y_test_1[:], alpha=0.01, max_iter=1000)\n",
    "\n",
    "\n",
    "# vec_X = np.reshape(X, (sample_size, -1)) # vectorizing data\n",
    "start = time.time()\n",
    "vec_svm_params = svmfit(X_train, Y_train_1)\n",
    "print(f\"time consumed SVM {time.time() - start} s\")\n",
    "vec_svm_reconstructed = np.reshape(vec_svm_params, (cp_svm_reconstructed.shape))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "y_pred2 = np.sign(np.inner(vec_svm_params, X_test))\n",
    "\n",
    "print(f\"time infer SVM {time.time() - start} s\")\n",
    "print('SVM acc', accuracy_score(Y_test_1, y_pred2))\n",
    "\n",
    "print('Traditional svm params = ', vec_svm_params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hf_train = h5py.File(\"./train_point_clouds.h5\", \"r\")  \n",
    "hf_test = h5py.File(\"./test_point_clouds.h5\", \"r\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube (dots):\n",
    "    cub = np.zeros((16,16,16))\n",
    "    ndots = dots.shape[0]\n",
    "    for dot in dots:\n",
    "        if dot[0] > 0.5:\n",
    "            dot[0] = 0.5\n",
    "        elif dot[0] < -0.5:\n",
    "            dot[0] = -0.5\n",
    "        if dot[1] > 0.5:\n",
    "            dot[1] = 0.5\n",
    "        elif dot[1] < -0.5:\n",
    "            dot[1] = -0.5\n",
    "        if dot[2] > 0.5:\n",
    "            dot[2] = 0.5\n",
    "        elif dot[2] < -0.5:\n",
    "            dot[2] = -0.5\n",
    "        dot[0] += 0.5\n",
    "        dot[1] += 0.5\n",
    "        dot[2] += 0.5\n",
    "        n1 = round(dot[0]/0.0625)\n",
    "        n2 = round(dot[1]/0.0625)\n",
    "        n3 = round(dot[2]/0.0625)\n",
    "        if n1 == 16:\n",
    "            n1 = 15\n",
    "        if n2 == 16:\n",
    "            n2 = 15\n",
    "        if n3 == 16:\n",
    "            n3 = 15\n",
    "        cub[n1][n2][n3] += 1/ndots\n",
    "        #if cub[n1][n2][n3] != 0:\n",
    "        #    print(cub[n1][n2][n3])\n",
    "    return cub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train_ones = []\n",
    "for i in range(1000):\n",
    "    if hf_train[str(i)].attrs['label'] == 1:\n",
    "        hf_train_ones.append(i)\n",
    "\n",
    "hf_test_ones = []\n",
    "for i in range(1000):\n",
    "    if hf_test[str(i)].attrs['label'] == 1:\n",
    "        hf_test_ones.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d_train = []\n",
    "y_3d_train = []\n",
    "X_d_train = []\n",
    "\n",
    "dots = 500\n",
    "\n",
    "for i in range(1000):\n",
    "    #inds = np.sort(np.random.choice(hf_train[str(i)]['points'].shape[0], dots, replace=False))\n",
    "    cub = cube(hf_train[str(i)]['points'][:, : ])\n",
    "    #hf_train[str(i)]['points'][inds, : ]\n",
    "    X_3d_train.append(cub)\n",
    "    X_d_train.append(cub.reshape(-1))\n",
    "    y_3d_train.append(hf_train[str(i)].attrs['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d_test = []\n",
    "y_3d_test = []\n",
    "X_d_test = []\n",
    "\n",
    "for i in range(100):\n",
    "    #inds = np.sort(np.random.choice(hf_test[str(i)]['points'].shape[0], dots, replace=False))\n",
    "    cub = cube(hf_test[str(i)]['points'][:, : ])\n",
    "    X_3d_test.append(cub)\n",
    "    #X_d_test.append(np.array(hf_test[str(i)]['points'][inds,  : ]).reshape(-1))\n",
    "    X_d_test.append(cub.reshape(-1))\n",
    "    y_3d_test.append(hf_test[str(i)].attrs['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3d_train= np.array(y_3d_train)\n",
    "y_3d_train_1 = (y_3d_train==1).astype(int)*2-1\n",
    "X_3d_train = np.array(X_3d_train)\n",
    "X_d_train = np.array(X_d_train)\n",
    "\n",
    "y_3d_test= np.array(y_3d_test)\n",
    "y_3d_test_1 = (y_3d_test==1).astype(int)*2-1\n",
    "X_3d_test = np.array(X_3d_test)\n",
    "X_d_test = np.array(X_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iteration: 1\n",
      "Current Difference in Error Value: 1.0000000000005234\n",
      "\n",
      "Current Iteration: 2\n",
      "Current Difference in Error Value: 1.1102230246251565e-15\n",
      "\n",
      "3D time consumed CP-SVM 8.588313102722168 s\n",
      "3D CP svm params =  144\n",
      "0.74\n",
      "time infer CP-SVM 0.0 s\n",
      "CP-SVM acc 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "CP_rank = 3\n",
    "\n",
    "# training CP SVM model\n",
    "CP_SVM = CP_LinearSVM(CP_rank=CP_rank)\n",
    "start = time.time()\n",
    "svm_dict = CP_SVM.fit(X_3d_train, y_3d_train_1)\n",
    "cp_svm_reconstructed = CP_SVM.reconstructTensor(solved_dict=svm_dict, tensor_n_dim=3) \n",
    "print(f\"3D time consumed CP-SVM {time.time() - start} s\")\n",
    "\n",
    "params = 0\n",
    "for i in svm_dict:\n",
    "    params += svm_dict[i].size\n",
    "print('3D CP svm params = ', params)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "y_pred = np.inner(cp_svm_reconstructed.reshape(-1), np.reshape(X_3d_test, (X_3d_test.shape[0], X_3d_test.shape[1]*X_3d_test.shape[2]*X_3d_test.shape[3])))\n",
    "y_pred_sign = np.sign(y_pred)\n",
    "\n",
    "predict = []\n",
    "for t in X_3d_test:\n",
    "    predict.append(np.sign(np.sum(t * cp_svm_reconstructed)))\n",
    "predict = np.array(predict)\n",
    "print(accuracy_score(y_3d_test_1, predict))\n",
    "\n",
    "print(f\"time infer CP-SVM {time.time() - start} s\")\n",
    "print('CP-SVM acc', accuracy_score(y_3d_test_1, y_pred_sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time consumed SVM 195.55845880508423 s\n",
      "SVM acc 0.86\n",
      "time infer SVM 0.0 s\n",
      "Traditional svm params =  (4096,)\n"
     ]
    }
   ],
   "source": [
    "vec_X = np.reshape(X_3d_train, (X_3d_train.shape[0], -1)) \n",
    "start = time.time()\n",
    "vec_svm_params = svmfit(vec_X, y_3d_train_1)\n",
    "print(f\"time consumed SVM {time.time() - start} s\")\n",
    "vec_svm_reconstructed = np.reshape(vec_svm_params, (cp_svm_reconstructed.shape))\n",
    "\n",
    "start = time.time()\n",
    "y_pred2 = np.sign(np.inner(vec_svm_params, np.reshape(X_3d_test, (X_3d_test.shape[0], X_3d_test.shape[1]*X_3d_test.shape[2]*X_3d_test.shape[3]))))\n",
    "print('SVM acc', accuracy_score(y_3d_test_1, y_pred2))\n",
    "print(f\"time infer SVM {time.time() - start} s\")\n",
    "\n",
    "\n",
    "\n",
    "print('Traditional svm params = ', vec_svm_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_ = CP_LogisticRegression(CP_rank=3) \n",
    "start = time.time()\n",
    "log_dict = CP_.fit(X_3d_train, y_3d_train_1, max_iterations=50, C = 0.0005)\n",
    "end = time.time()\n",
    "\n",
    "cp_reconstructed = CP_.reconstructTensor(solved_dict=log_dict, tensor_n_dim=3) \n",
    "\n",
    "print(f\"time consumed {end - start} s\")\n",
    "predict = []\n",
    "for t in X_3d_test:\n",
    "    predict.append(expit(np.sum(t * cp_reconstructed)))\n",
    "predict = np.array(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
